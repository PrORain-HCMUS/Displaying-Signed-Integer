{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/videos'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2024-08-31T04:26:01.041201Z","iopub.execute_input":"2024-08-31T04:26:01.042117Z","iopub.status.idle":"2024-08-31T04:26:01.478184Z","shell.execute_reply.started":"2024-08-31T04:26:01.042065Z","shell.execute_reply":"2024-08-31T04:26:01.477196Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/videos/L12_V017.mp4\n/kaggle/input/videos/L11_V008.mp4\n/kaggle/input/videos/L11_V012.mp4\n/kaggle/input/videos/L11_V029.mp4\n/kaggle/input/videos/L12_V002.mp4\n/kaggle/input/videos/L11_V020.mp4\n/kaggle/input/videos/L12_V007.mp4\n/kaggle/input/videos/L12_V025.mp4\n/kaggle/input/videos/L11_V028.mp4\n/kaggle/input/videos/L12_V008.mp4\n/kaggle/input/videos/L12_V018.mp4\n/kaggle/input/videos/L12_V015.mp4\n/kaggle/input/videos/L12_V024.mp4\n/kaggle/input/videos/L11_V017.mp4\n/kaggle/input/videos/L12_V029.mp4\n/kaggle/input/videos/L12_V028.mp4\n/kaggle/input/videos/L11_V010.mp4\n/kaggle/input/videos/L12_V020.mp4\n/kaggle/input/videos/L12_V014.mp4\n/kaggle/input/videos/L11_V011.mp4\n/kaggle/input/videos/L11_V021.mp4\n/kaggle/input/videos/L11_V001.mp4\n/kaggle/input/videos/L12_V021.mp4\n/kaggle/input/videos/L11_V014.mp4\n/kaggle/input/videos/L11_V003.mp4\n/kaggle/input/videos/L12_V022.mp4\n/kaggle/input/videos/L11_V015.mp4\n/kaggle/input/videos/L12_V030.mp4\n/kaggle/input/videos/L12_V005.mp4\n/kaggle/input/videos/L11_V005.mp4\n/kaggle/input/videos/L12_V016.mp4\n/kaggle/input/videos/L11_V026.mp4\n/kaggle/input/videos/L11_V004.mp4\n/kaggle/input/videos/L12_V001.mp4\n/kaggle/input/videos/L12_V004.mp4\n/kaggle/input/videos/L11_V006.mp4\n/kaggle/input/videos/L11_V027.mp4\n/kaggle/input/videos/L12_V026.mp4\n/kaggle/input/videos/L12_V023.mp4\n/kaggle/input/videos/L11_V022.mp4\n/kaggle/input/videos/L12_V009.mp4\n/kaggle/input/videos/L11_V030.mp4\n/kaggle/input/videos/L12_V010.mp4\n/kaggle/input/videos/L12_V019.mp4\n/kaggle/input/videos/L12_V006.mp4\n/kaggle/input/videos/L11_V024.mp4\n/kaggle/input/videos/L11_V025.mp4\n/kaggle/input/videos/L12_V027.mp4\n/kaggle/input/videos/L11_V013.mp4\n/kaggle/input/videos/L11_V009.mp4\n/kaggle/input/videos/L12_V012.mp4\n/kaggle/input/videos/L12_V013.mp4\n/kaggle/input/videos/L11_V016.mp4\n/kaggle/input/videos/L11_V019.mp4\n/kaggle/input/videos/L11_V002.mp4\n/kaggle/input/videos/L11_V023.mp4\n/kaggle/input/videos/L12_V003.mp4\n/kaggle/input/videos/L11_V007.mp4\n/kaggle/input/videos/L11_V018.mp4\n/kaggle/input/videos/L12_V011.mp4\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install opencv-python-headless numpy\n!git clone https://github.com/soCzech/TransNetV2\n%cd TransNetV2/inference\n# !pip install google","metadata":{"execution":{"iopub.status.busy":"2024-08-31T04:26:15.431811Z","iopub.execute_input":"2024-08-31T04:26:15.432312Z","iopub.status.idle":"2024-08-31T04:26:33.620079Z","shell.execute_reply.started":"2024-08-31T04:26:15.432271Z","shell.execute_reply":"2024-08-31T04:26:33.618816Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nCloning into 'TransNetV2'...\nremote: Enumerating objects: 362, done.\u001b[K\nremote: Counting objects: 100% (84/84), done.\u001b[K\nremote: Compressing objects: 100% (14/14), done.\u001b[K\nremote: Total 362 (delta 70), reused 70 (delta 70), pack-reused 278 (from 1)\u001b[K\nReceiving objects: 100% (362/362), 95.27 KiB | 1.29 MiB/s, done.\nResolving deltas: 100% (210/210), done.\nFiltering content: 100% (3/3), 34.77 MiB | 21.77 MiB/s, done.\n/kaggle/working/TransNetV2/inference\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport zipfile\nfrom transnetv2 import TransNetV2\nfrom IPython.display import FileLink, HTML\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T02:31:30.305365Z","iopub.execute_input":"2024-08-29T02:31:30.305886Z","iopub.status.idle":"2024-08-29T02:31:42.536738Z","shell.execute_reply.started":"2024-08-29T02:31:30.305844Z","shell.execute_reply":"2024-08-29T02:31:42.53572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_paths = []\nfor dirname, _, filenames in os.walk('/kaggle/input/videos'):\n    for filename in filenames:\n        video_path = os.path.join(dirname, filename)\n        if os.path.exists(video_path):\n            video_paths.append(video_path)\nvideo_paths.sort()\nprint(video_paths)","metadata":{"execution":{"iopub.status.busy":"2024-08-29T02:32:17.70031Z","iopub.execute_input":"2024-08-29T02:32:17.701117Z","iopub.status.idle":"2024-08-29T02:32:17.788318Z","shell.execute_reply.started":"2024-08-29T02:32:17.701076Z","shell.execute_reply":"2024-08-29T02:32:17.787337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_folder = '/kaggle/working/output'\n    \nif not os.path.exists(output_folder):\n  os.makedirs(output_folder)\n\nmodel = TransNetV2()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T02:32:21.033286Z","iopub.execute_input":"2024-08-29T02:32:21.033941Z","iopub.status.idle":"2024-08-29T02:32:27.485802Z","shell.execute_reply.started":"2024-08-29T02:32:21.033902Z","shell.execute_reply":"2024-08-29T02:32:27.484945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getSceneFrames(video_path: str):\n    folder_name = video_path.split('/')[-1].replace('.mp4', '')\n    \n    result_folder = f'{output_folder}/{folder_name}'\n    \n    if not os.path.exists(result_folder):\n        os.makedirs(result_folder)\n    \n    keyframes_folder = f'{result_folder}/keyframes'\n    \n    if not os.path.exists(keyframes_folder):\n        os.makedirs(keyframes_folder)\n\n    keyframes_mapping_json = f'{result_folder}/{folder_name}.json'\n\n    \n    # Ensure the directory for JSON file exists, not the file itself\n    child_mapping_dir = os.path.dirname(keyframes_mapping_json)\n    if not os.path.exists(child_mapping_dir):\n        os.makedirs(child_mapping_dir)\n    \n    # Make sure that no directory exists with the same name as the JSON file\n    if os.path.isdir(keyframes_mapping_json):\n        print(f\"Error: {keyframes_mapping_json} is a directory, not a file.\")\n        return\n       \n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if ret:\n            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            frame_resized = cv2.resize(frame_rgb, (48, 27))\n            frames.append(frame_resized)\n        else:\n            break\n\n    cap.release()\n\n    frames = np.array(frames)\n\n    predictions = model.predict_frames(frames)\n    \n    prediction, prediction_changes = predictions\n\n    scene_changes = np.where(prediction_changes > 0.85)[0]\n\n    scene_changes_updated = []\n\n    for i in range(1, len(scene_changes)):\n        if scene_changes[i] - scene_changes[i - 1] > 1:\n            scene_changes_updated.append(scene_changes[i - 1])\n\n    if scene_changes[-1] - scene_changes[-2] > 1:\n        scene_changes_updated.append(scene_changes[-1])\n    else:\n        scene_changes_updated.pop()\n        scene_changes_updated.append(scene_changes[-1])\n    \n    frames_mapping_dict = {}\n    current_frames = []\n    frame_index = 0\n    index = 0\n    \n    cap = cv2.VideoCapture(video_path)\n    \n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        if frame_index in scene_changes or frame_index == len(frames) - 1:\n            len_frames = len(current_frames)\n            if len_frames > 2:\n                start_frame = current_frames[0]\n                middle_frame = current_frames[len_frames // 2]\n                end_frame = current_frames[len_frames - 1]\n\n                cv2.imwrite(os.path.join(keyframes_folder, f\"{index}.jpg\"), start_frame)\n                cv2.imwrite(os.path.join(keyframes_folder, f\"{index + 1}.jpg\"), middle_frame)\n                cv2.imwrite(os.path.join(keyframes_folder, f\"{index + 2}.jpg\"), end_frame)\n\n                frames_mapping_dict[index] = frame_index - len_frames\n                frames_mapping_dict[index + 1] = frame_index - len_frames + len_frames // 2\n                frames_mapping_dict[index + 2] = frame_index - 1\n\n                current_frames = []\n                index += 3\n\n        else:\n            current_frames.append(frame)\n            \n        frame_index += 1\n\n    cap.release()\n        \n    # Write the mapping to the JSON file\n    with open(keyframes_mapping_json, 'w') as json_file:\n        json.dump(frames_mapping_dict, json_file, indent=4)\n    \n    print(f\"Lưu thành công {index // 3} đoạn video và 1 file keyframe-mapping vào thư mục {result_folder}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T02:32:29.890713Z","iopub.execute_input":"2024-08-29T02:32:29.891106Z","iopub.status.idle":"2024-08-29T02:32:29.908604Z","shell.execute_reply.started":"2024-08-29T02:32:29.89107Z","shell.execute_reply":"2024-08-29T02:32:29.907525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compress_to_zip(video_path, output_folder):\n    \n    folder_name = video_path.split('/')[-1].replace('.mp4', '')\n    \n    input_folder = f'{output_folder}/{folder_name}'\n\n    # Đặt tên cho file zip đầu ra\n    output_zip = f'/kaggle/working/{folder_name}.zip'\n    \n    download_path = f\"https://kkb-production.jupyter-proxy.kaggle.net/k/194493829/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..sKAZVNzwRVzG1ZFJGD_BbA.bFaQ9PSjVhClJHFXxNbGZHdnac7S5HYRS2bUq-FTjasns-6-j0lRyCsC8aGwIqsWbAuLamLiyBZr3sIOLRJ90MEj11lh1YHAbp6G9l9-3tK_NtyRY65jUkGmEC-HYkU-NBmcxiEVOmxelzvk9hHvkS9EGPjr2l6t7kegs5oTlMruRZOZq7LsrYQdifLfEoDlRD8-L7WKd_jDwG5Kt3qv9A.qsBo-R09cdVqCyJfodN8ZQ/proxy/files/{folder_name}.zip\"\n    \n    # Tạo file zip\n    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(input_folder):\n            for file in files:\n                file_path = os.path.join(root, file)\n                # Thêm file vào zip, giữ nguyên cấu trúc thư mục\n                zipf.write(file_path, os.path.relpath(file_path, input_folder))\n\n    print(f\"Folder zipped to {output_zip}\")\n    \n    # Hiển thị link tải về\n    display(HTML(f'<a href=\"{download_path}\" target=\"_blank\">Click here to download {output_zip} ZIP file</a>'))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T02:40:05.433106Z","iopub.execute_input":"2024-08-29T02:40:05.433829Z","iopub.status.idle":"2024-08-29T02:40:05.441061Z","shell.execute_reply.started":"2024-08-29T02:40:05.433791Z","shell.execute_reply":"2024-08-29T02:40:05.440042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def release_folder(video_path:str):\n    folder_name = video_path.split('/')[-1].replace('.mp4', '')\n    \n    result_folder = f'{output_folder}/{folder_name}'\n    \n    folder_path = f'{result_folder}/keyframes'\n    \n    if os.path.exists(folder_path):\n        for filename in os.listdir(folder_path):\n            file_path = os.path.join(folder_path, filename)\n\n            if os.path.isfile(file_path):\n                os.remove(file_path)\n                print(f'Deleted file: {file_path}')\n    else:\n        print('The specified folder does not exist')","metadata":{"execution":{"iopub.status.busy":"2024-08-29T02:32:38.745612Z","iopub.execute_input":"2024-08-29T02:32:38.7465Z","iopub.status.idle":"2024-08-29T02:32:38.752829Z","shell.execute_reply.started":"2024-08-29T02:32:38.746435Z","shell.execute_reply":"2024-08-29T02:32:38.7519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for video_path in video_paths:\n    getSceneFrames(video_path)\n    compress_to_zip(video_path, output_folder)\n\n# getSceneFrames(video_paths[0])\n# compress_to_zip(output_folder, output_zip)\n\n# release_folder(video_paths[0])\n# release_folder(video_paths[1])","metadata":{"execution":{"iopub.status.busy":"2024-08-29T02:40:08.35431Z","iopub.execute_input":"2024-08-29T02:40:08.355253Z","iopub.status.idle":"2024-08-29T05:26:23.510255Z","shell.execute_reply.started":"2024-08-29T02:40:08.355209Z","shell.execute_reply":"2024-08-29T05:26:23.50934Z"},"trusted":true},"execution_count":null,"outputs":[]}]}